---
title: "Building first baseline with random forest using ranger and DALEX"
author: "Olga Mierzwa-Sulima"
date: '2020-09-30'
tags:
- random forest
- variable importance
- DALEX
- ranger
- r
categories: data-science
---



<div id="tltr" class="section level1">
<h1>tltr</h1>
<p>I show an approach to building a first baseline model using random forest (RF).
I use <code>DALEX</code> package to understand a random forest built with <code>ranger</code> package, simplify it, improve performance, and run time. I use <code>recipes</code> package to handle categorical variables, missing values, and novel levels.</p>
<div id="random-forest-and-first-baseline" class="section level2">
<h2>Random forest and first baseline</h2>
<p>Random forest is a powerful and flexible model that is relatively easy to tune. This is why it‚Äôs usually a top candidate to start with and build the first baseline. Establishing a baseline as soon as possible when modeling is a must otherwise if you run a new experiment you don‚Äôt know if you manage to improve or not.
When starting with RF is not a good idea? Unless you have the data with a very strong time component RF is not a good idea as it <a href="https://neptune.ai/blog/random-forest-regression-when-does-it-fail-and-why">can‚Äôt extrapolate</a>.</p>
</div>
<div id="variable-importance" class="section level2">
<h2>Variable importance</h2>
<p>Feature or variable importance let‚Äôs you understand which features are important in a given machine learning model. Usually there is only a handful of variables that are important and you want to care about when building and understanding a model.</p>
<p>The main idea behind variable importance is to measure how much the model fit decreases if the effect of a variable is removed. The effect is removed by permuting the column. Values still have the same distribution but it‚Äôs relation to the dependent variable is gone. If a variable is important, then after random shuffling the model performance should decrease. The larger drop in the performance, the more important is the variable. Read more about pros and cons of this approach in the <a href="https://pbiecek.github.io/ema/featureImportance.html">Explanatory Model Analysis. Explore, Explain and Examine Predictive Models e-book</a>.</p>
<p><code>DALEX</code> package in R offers this powerful and model agnostic way of calculating variable importance.</p>
<div id="how-does-it-affect-model-performance" class="section level3">
<h3>How does it affect model performance?</h3>
<p>Dropping unimportant columns should not decrease the model performance. By removing a bunch of columns we can get rid of the source of collinearity between the features. The importance that previously was split between the columns should only be reflected in the one left in the model. This makes the feature importance values more clear and reliable.</p>
<p>For example random forest has less columns to try making a split, so it has a slightly better chance to make a better decisions. Model should take less time to run.</p>
<p>The biggest gain comes in less variables that a modeler needs to understand and worry in a model.</p>
</div>
</div>
<div id="analysis-approach" class="section level2">
<h2>Analysis approach</h2>
<p>The main idea is to build a RF model as soon as possible without thinking too much about the data and use model interpretation techniques to make it better. Image that you get to build a model in the domain you know little about, so it‚Äôs difficult to judge which features might play an important role. Turns out you can use modelling to find out which ones are important and only focus on them in the later stages of analysis.
I use <a href="https://www.kaggle.com/c/bluebook-for-bulldozers/data">Blue Book for Bulldozers</a> data from Kaggle‚Äôs and predict an auction price for a heavy equipment with a random forest.
I build a model on a data which I pre-process in a very limited way using <code>recipes</code> package, just so <code>ranger</code> package can actually works.
After I have the model I plug it into <code>DALEX</code> explainer, perform variable importance shuffling and visualize the results. Next by interpreting the results I make adjustments to the
Example is inspired by <a href="https://www.fast.ai/">fast.ai</a> analysis from the book <a href="https://github.com/fastai/fastbook">Deep Learning for Coders</a> chapter on tabular learner‚Äôs. I show how to do a similar analysis using tools available in R.</p>
</div>
<div id="solution-in-r" class="section level2">
<h2>Solution in R</h2>
<p>Read in R packages.</p>
<pre class="r"><code>library(tidyverse)
library(lubridate)
library(ranger)
library(DALEX)
library(tidymodels)
library(rlang)</code></pre>
<p>Read in data.</p>
<pre class="r"><code>data_raw &lt;- readr::read_csv(file = &quot;data/Train.csv&quot;)</code></pre>
<div id="data-pre-processing" class="section level3">
<h3>Data pre-processing</h3>
<p>There are few things to be done with the data before pluging them into the model.
* I need to handle missing data both in numeric and cardinal columns. In the numeric columns missing values are replaced with median with a <code>recipe</code> step <code>step_medianimpute()</code>. I add a dummy column for every numeric column that contains NAs using <code>add_dummy_for_na_numeric()</code> that I define myself.
I replace NAs in character columns with ‚ÄúNA‚Äù string and threat missing values as a separate level.
* I make sure my cardinal variables enter the model as factors. I use <code>recipe</code> <code>step_novel()</code> to make sure model can handle unseen levels in the validation set.
* I add new features based on sale date column to help the model handle time better. New features are: elapsed number of days since 1 Jan 1970, day, week, month, year, day of week, day of year and indicators is year/quarter/month beginning/end and are added using <code>proc_date()</code>.</p>
<pre class="r"><code>add_dummy_for_na_numeric &lt;- function(x){
  x %&gt;%
    mutate_if(~any(is.na(.)) &amp; is.numeric(.),
              .funs = list(na = ~if_else(is.na(.), 1, 0)))
}

proc_date &lt;- function(data, var_name) {
  data %&gt;%
    dplyr::mutate(
      elapsed = floor(unclass(as.POSIXct({{var_name}}))/86400),
      year = lubridate::year({{var_name}}),
      month = lubridate::month({{var_name}}),
      day = lubridate::day({{var_name}}),
      week = lubridate::week({{var_name}}),
      day_of_week = lubridate::wday({{var_name}}),
      day_of_year = lubridate::yday({{var_name}}),
      is_end_of_month = if_else({{var_name}} == (ceiling_date({{var_name}}, unit = &quot;month&quot;) - 1), TRUE, FALSE),
      is_begining_of_month = if_else({{var_name}} == floor_date({{var_name}}, unit = &quot;month&quot;), TRUE, FALSE),
      is_end_of_quarter = if_else({{var_name}} == (ceiling_date({{var_name}}, unit = &quot;quarter&quot;) - 1), TRUE, FALSE),
      is_begining_of_quarter = if_else({{var_name}} == floor_date({{var_name}}, unit = &quot;quarter&quot;), TRUE, FALSE),
      is_end_of_year = if_else({{var_name}} == (ceiling_date({{var_name}}, unit = &quot;year&quot;) - 1), TRUE, FALSE),
      is_begining_of_year = if_else({{var_name}} == floor_date({{var_name}}, unit = &quot;year&quot;), TRUE, FALSE)
      
    )
    
}</code></pre>
<p>Pre-process data by calling helper functions:</p>
<pre class="r"><code>data_after_basic_preprocess &lt;- data_raw %&gt;%
  dplyr::mutate(
    saledate = lubridate::as_date(saledate, format = &quot;%m/%d/%Y %H:%M&quot;)
    ) %&gt;%
  arrange(saledate) %&gt;% 
  proc_date(saledate) %&gt;% 
  mutate_if(is_character, ~if_else(is.na(.), &quot;NA&quot;, .)) %&gt;% 
  add_dummy_for_na_numeric()</code></pre>
<p>I take the log of <code>SalePrice</code>. Taking the log of the <code>SalePrice</code> makes the variable normally distributed and changes the relative distance between numbers.</p>
<pre class="r"><code>data_step1 &lt;- data_after_basic_preprocess %&gt;%
  mutate(log_SalePrice = log(SalePrice),
         saledate = NULL,
         SalePrice = NULL)</code></pre>
<p>Split data into training and validation set using <code>initial_time_split()</code> function. I keep 80% of data in the training set and 20% in the validation. <code>initial_time_split()</code> is called on data which is sorted based on <code>saledate</code> so I make sure validation set contains ‚Äúfuture sales‚Äù. Taking a random sample would be cheating here, as we would use ‚Äúfuture information‚Äù to predict the past.</p>
<pre class="r"><code>data_step1_split &lt;- initial_time_split(data = data_step1, prop = 0.80)

train_set &lt;- training(data_step1_split)

valid_set &lt;- testing(data_step1_split)</code></pre>
<p>The rest of the pre-processing is done using <code>recipes</code> package:
* Replacing NAs in numeric columns with their median with <code>step_medianimpute()</code>
* Changing characters to factors with <code>step_string2factor()</code></p>
<p>Additionally <code>recipe()</code> takes care of new levels in validation set using <code>step_novel()</code>.</p>
<pre class="r"><code>recipe_formula &lt;-  recipe(log_SalePrice ~ ., data = data_step1_split)

recipe_steps &lt;- recipe_formula %&gt;%
  step_novel(all_nominal()) %&gt;% 
  step_medianimpute(all_numeric()) %&gt;%
  step_string2factor(all_nominal())

recipe_steps_on_training &lt;- recipe_steps %&gt;% 
  prep(train_set)</code></pre>
<p>Now let‚Äôs <code>juice</code> and <code>bake</code> training and validation sets and split <code>x</code> and <code>y</code> for <code>ranger</code> model to avoid using formula.</p>
<pre class="r"><code>train_set_preped &lt;- recipe_steps_on_training %&gt;%
  juice()

y_train &lt;- train_set_preped$log_SalePrice
x_train &lt;- train_set_preped %&gt;% select(-log_SalePrice)


valid_set_preped &lt;- recipe_steps_on_training %&gt;%
  bake(valid_set)

x_valid &lt;- valid_set_preped %&gt;% select(-log_SalePrice)
y_valid &lt;- valid_set_preped$log_SalePrice</code></pre>
</div>
<div id="model-building" class="section level3">
<h3>Model building</h3>
<p>I build random forest using <code>ranger</code> package. I‚Äôm not using <code>randomForest</code>, because it has very slow implementation in R.
I limit the number of trees to speed the training process to 40.</p>
<p>To avoid over-fitting:</p>
<ul>
<li>use a subset of columns when building trees by setting <code>mtry</code> parameter to build less correlated trees,</li>
<li>use a subset of rows when building trees by setting <code>sample.fraction</code>, can be used to build less correlated trees and speed up training,</li>
<li>stop training the tree further when a leaf node has 3 or less samples. Numbers that usually works well 1, 3, 5, 10, 25.</li>
</ul>
<p>Categorical variables enter the model as factors and ranger will treat them as ordered. This might seem controversial, but it has been <a href="https://peerj.com/articles/6339/">shown</a> by the one of the <code>ranger</code> authors Marvin Wrigth and Inke K√∂nig that treating factors like that shouldn‚Äôt impact final result, but is computationally more efficient.</p>
<pre class="r"><code>system.time(ranger_model_with_sampling &lt;- ranger(x = x_train,
                       y = y_train,
                       num.trees = 40,
                       mtry = (ncol(x_train) / 2), 
                       seed = 1,
                       min.node.size = 3,
                       sample.fraction = 1,
                       respect.unordered.factors = &quot;ignore&quot;
                       ))</code></pre>
<pre><code>## Growing trees.. Progress: 13%. Estimated remaining time: 4 minutes, 12 seconds.
## Growing trees.. Progress: 33%. Estimated remaining time: 2 minutes, 31 seconds.
## Growing trees.. Progress: 53%. Estimated remaining time: 1 minute, 36 seconds.
## Growing trees.. Progress: 73%. Estimated remaining time: 54 seconds.
## Growing trees.. Progress: 93%. Estimated remaining time: 14 seconds.</code></pre>
<pre><code>##    user  system elapsed 
## 603.448   2.242 186.687</code></pre>
<pre class="r"><code>ranger_predictions &lt;- predict(ranger_model_with_sampling, x_valid)

rmse &lt;- function(preds, y){
  sqrt(mean((preds - y)**2))
}
eval_model &lt;- function(model, y, y_valid, model_predictions) {
  c(model$r.squared,
      rmse(model$predictions, y),
      rmse(model_predictions, y_valid)
  )
}

eval_model(
  ranger_model_with_sampling, y_train, y_valid, ranger_predictions$predictions)</code></pre>
<pre><code>## [1] 0.9106202 0.2062955 0.2664465</code></pre>
</div>
<div id="model-interpretation" class="section level3">
<h3>Model interpretation</h3>
<p>Now when I have my random forest built I can try to understand it and look at variable importance plot. I use <code>DALEX</code> package and create <code>ranger</code> explainer. <code>DALEX</code> package provides tones of useful tools for understanding black box models.</p>
<pre class="r"><code>explainer_ranger  &lt;- explain(ranger_model_with_sampling,
                             data = x_train,
                             y = y_train)</code></pre>
<pre><code>## Preparation of a new explainer is initiated
##   -&gt; model label       :  ranger  ( [33m default [39m )
##   -&gt; data              :  320900  rows  66  cols 
##   -&gt; data              :  tibble converted into a data.frame 
##   -&gt; target variable   :  320900  values 
##   -&gt; predict function  :  yhat.ranger  will be used ( [33m default [39m )
##   -&gt; predicted values  :  numerical, min =  8.480695 , mean =  10.09761 , max =  11.84336  
##   -&gt; model_info        :  package ranger , ver. 0.12.1 , task regression ( [33m default [39m ) 
##   -&gt; residual function :  difference between y and yhat ( [33m default [39m )
##   -&gt; residuals         :  numerical, min =  -1.185159 , mean =  -7.183829e-05 , max =  0.9795716  
##  [32m A new explainer has been created! [39m</code></pre>
<p>I use <code>variable_importance()</code> function from <code>ingredients</code> (DALEX family) package to calculate the variable importance. My loss function is RMSE. DALEX performs by default 10 permutation rounds. I will average the permutation results and inspect the plot for the best 30 features (for better plot readability).
I drop <code>_baseline_</code> from the plot. Baseline is the change in model performance when all variables are permuted.</p>
<pre class="r"><code>var_importance &lt;- variable_importance(explainer_ranger,
                                      loss = loss_root_mean_square,
                                      B = 10,
                                      type = &quot;raw&quot;)

summarize_vi &lt;- var_importance %&gt;%
  group_by(variable) %&gt;% 
  summarize(mean_dropout_loss = mean(dropout_loss), .groups = &quot;keep&quot;) %&gt;%
  arrange(-mean_dropout_loss) %&gt;%
  mutate(variable = factor(variable, levels = variable))  

ggplot(data = summarize_vi[2:31,],
       aes(y = mean_dropout_loss, x = variable, group = 1)) +
  geom_line() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))</code></pre>
<p><img src="/post/2020-09-30-improve-rf-with-vi_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<p>There are only few variables that my random forest cares about. <code>YearMade</code> is the most important one.
So next I select the features before the curve flattens almost completely at around 0.1 mean dropout loss and build a model on the remaining features subset.</p>
<pre class="r"><code>var_to_keep &lt;-  summarize_vi %&gt;%
  filter(mean_dropout_loss &gt; 0.1 &amp; variable != &quot;_baseline_&quot;) %&gt;% 
  select(variable)

x_after_var_importance &lt;- x_train %&gt;% select(var_to_keep$variable)</code></pre>
<pre class="r"><code>system.time(ranger_model_after_vi &lt;- ranger(x = x_after_var_importance,
                       y = y_train,
                       num.trees = 40,
                       mtry = (ncol(x_after_var_importance) / 2),
                       seed = 1,
                       respect.unordered.factors = F,
                       min.node.size = 3,
                       sample.fraction = 1))</code></pre>
<pre><code>## Growing trees.. Progress: 53%. Estimated remaining time: 28 seconds.</code></pre>
<pre><code>##    user  system elapsed 
## 211.841   0.877  62.166</code></pre>
<pre class="r"><code>ranger_predictions_after_vi &lt;- predict(ranger_model_after_vi,
                                       x_valid %&gt;% select(var_to_keep$variable))

eval_model(
  ranger_model_after_vi, y_train, y_valid, ranger_predictions_after_vi$predictions)</code></pre>
<pre><code>## [1] 0.9089519 0.2082119 0.2692650</code></pre>
<p>I end up with a simpler model with almost the same quality, differences in R^2 and RMSE are neglectable. I prefer to continue with model with less features which runs faster.</p>
<p>Let‚Äôs again look at variable importance plot and do more digging.</p>
<pre class="r"><code>explainer_ranger_after_vi  &lt;- explain(ranger_model_after_vi,
                                      data = x_after_var_importance,
                                      y = y_train)</code></pre>
<pre><code>## Preparation of a new explainer is initiated
##   -&gt; model label       :  ranger  ( [33m default [39m )
##   -&gt; data              :  320900  rows  18  cols 
##   -&gt; data              :  tibble converted into a data.frame 
##   -&gt; target variable   :  320900  values 
##   -&gt; predict function  :  yhat.ranger  will be used ( [33m default [39m )
##   -&gt; predicted values  :  numerical, min =  8.482757 , mean =  10.09765 , max =  11.84426  
##   -&gt; model_info        :  package ranger , ver. 0.12.1 , task regression ( [33m default [39m ) 
##   -&gt; residual function :  difference between y and yhat ( [33m default [39m )
##   -&gt; residuals         :  numerical, min =  -1.201127 , mean =  -0.0001043412 , max =  0.9551131  
##  [32m A new explainer has been created! [39m</code></pre>
<pre class="r"><code>var_importance_ranger_after_vi &lt;- variable_importance(
  explainer_ranger_after_vi,
  loss_function = loss_root_mean_square,
  B = 10,
  type = &quot;raw&quot;)

plot(var_importance_ranger_after_vi)</code></pre>
<p><img src="/post/2020-09-30-improve-rf-with-vi_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<p><code>YearMade</code> is the most important feature for my model. It would be interesting to learn more about this variable.
Second thing that stands out is how important are SalesID and MachineId. I expect these are unique identifiers so it‚Äôs strange they are so important. So it‚Äôs another thing worth looking into.</p>
<pre class="r"><code>ggplot(data_step1, aes(x = YearMade)) + 
  geom_histogram(binwidth = 10)</code></pre>
<p><img src="/post/2020-09-30-improve-rf-with-vi_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
<pre class="r"><code>data_step1 %&gt;% group_by(YearMade) %&gt;% count()</code></pre>
<pre><code>## # A tibble: 72 x 2
## # Groups:   YearMade [72]
##    YearMade     n
##       &lt;dbl&gt; &lt;int&gt;
##  1     1000 38185
##  2     1919   127
##  3     1920    17
##  4     1937     1
##  5     1942     1
##  6     1947     1
##  7     1948     3
##  8     1949     1
##  9     1950     8
## 10     1951     7
## # ‚Ä¶ with 62 more rows</code></pre>
<p>After plotting YearMade distribution I can see that sth weird is happening. There is 38185 entries with YearMade 1000. This is not possible, so I remove this data and use the sales after the War ended.</p>
<pre class="r"><code>data_step1$SalesID %&gt;% n_distinct()</code></pre>
<pre><code>## [1] 401125</code></pre>
<pre class="r"><code>data_step1$MachineID %&gt;% n_distinct()</code></pre>
<pre><code>## [1] 341027</code></pre>
<pre class="r"><code>data_step1 %&gt;%
  filter(MachineID == 2283592)</code></pre>
<pre><code>## # A tibble: 26 x 67
##    SalesID MachineID ModelID datasource auctioneerID YearMade MachineHoursCur‚Ä¶
##      &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;            &lt;dbl&gt;
##  1 4319298   2283592    4579        172            1     2002             3802
##  2 4319348   2283592    4579        172            1     2006             1764
##  3 4319347   2283592    4579        172            1     2006              831
##  4 4319295   2283592    4579        172            1     2005                0
##  5 4319353   2283592    4579        172            1     2004             3405
##  6 4319296   2283592    4579        172            1     2004             3405
##  7 4319355   2283592    4579        172            1     2005             2201
##  8 4319294   2283592    4579        172            1     2005             2201
##  9 4319350   2283592    4579        172            1     2005             2050
## 10 4319335   2283592    4579        172            1     2005             2050
## # ‚Ä¶ with 16 more rows, and 60 more variables: UsageBand &lt;chr&gt;,
## #   fiModelDesc &lt;chr&gt;, fiBaseModel &lt;chr&gt;, fiSecondaryDesc &lt;chr&gt;,
## #   fiModelSeries &lt;chr&gt;, fiModelDescriptor &lt;chr&gt;, ProductSize &lt;chr&gt;,
## #   fiProductClassDesc &lt;chr&gt;, state &lt;chr&gt;, ProductGroup &lt;chr&gt;,
## #   ProductGroupDesc &lt;chr&gt;, Drive_System &lt;chr&gt;, Enclosure &lt;chr&gt;, Forks &lt;chr&gt;,
## #   Pad_Type &lt;chr&gt;, Ride_Control &lt;chr&gt;, Stick &lt;chr&gt;, Transmission &lt;chr&gt;,
## #   Turbocharged &lt;chr&gt;, Blade_Extension &lt;chr&gt;, Blade_Width &lt;chr&gt;,
## #   Enclosure_Type &lt;chr&gt;, Engine_Horsepower &lt;chr&gt;, Hydraulics &lt;chr&gt;,
## #   Pushblock &lt;chr&gt;, Ripper &lt;chr&gt;, Scarifier &lt;chr&gt;, Tip_Control &lt;chr&gt;,
## #   Tire_Size &lt;chr&gt;, Coupler &lt;chr&gt;, Coupler_System &lt;chr&gt;, Grouser_Tracks &lt;chr&gt;,
## #   Hydraulics_Flow &lt;chr&gt;, Track_Type &lt;chr&gt;, Undercarriage_Pad_Width &lt;chr&gt;,
## #   Stick_Length &lt;chr&gt;, Thumb &lt;chr&gt;, Pattern_Changer &lt;chr&gt;, Grouser_Type &lt;chr&gt;,
## #   Backhoe_Mounting &lt;chr&gt;, Blade_Type &lt;chr&gt;, Travel_Controls &lt;chr&gt;,
## #   Differential_Type &lt;chr&gt;, Steering_Controls &lt;chr&gt;, elapsed &lt;dbl&gt;,
## #   year &lt;dbl&gt;, month &lt;dbl&gt;, day &lt;int&gt;, week &lt;dbl&gt;, day_of_week &lt;dbl&gt;,
## #   day_of_year &lt;dbl&gt;, is_end_of_month &lt;lgl&gt;, is_begining_of_month &lt;lgl&gt;,
## #   is_end_of_quarter &lt;lgl&gt;, is_begining_of_quarter &lt;lgl&gt;,
## #   is_end_of_year &lt;lgl&gt;, is_begining_of_year &lt;lgl&gt;, auctioneerID_na &lt;dbl&gt;,
## #   MachineHoursCurrentMeter_na &lt;dbl&gt;, log_SalePrice &lt;dbl&gt;</code></pre>
<p>SalesID is a unique identifier that sorts sales from the oldest to the newest.
Kaggle‚Äôs description says MachineID is unique machine identifier and that machine can be sold multiple times. I expect that RF model could be overfitting on these columns so I remove them from the dataset and see how it impacts the model.</p>
<pre class="r"><code>x_train &lt;- x_train %&gt;%
  mutate(YearMade = if_else(YearMade &gt;= 1950, YearMade, 1950)) %&gt;%
  select(var_to_keep$variable) %&gt;%
  select(-c(SalesID, MachineID))

x_valid &lt;- x_valid %&gt;%
  mutate(YearMade = if_else(YearMade &gt;= 1950, YearMade, 1950)) %&gt;%
  select(var_to_keep$variable) %&gt;%
  select(-c(SalesID, MachineID))</code></pre>
<pre class="r"><code>system.time(ranger_model_after_vi_data_clean &lt;- ranger(x = x_train,
                       y = y_train,
                       num.trees = 40,
                       mtry = (ncol(x_train) / 2),
                       seed = 1,
                       min.node.size = 3,
                       sample.fraction = 1))</code></pre>
<pre><code>## Growing trees.. Progress: 60%. Estimated remaining time: 20 seconds.</code></pre>
<pre><code>##    user  system elapsed 
## 159.987   0.800  52.192</code></pre>
<pre class="r"><code>ranger_predictions_after_vi_clean &lt;- predict(ranger_model_after_vi_data_clean,
                                       x_valid)

eval_model(
  ranger_model_after_vi_data_clean, y_train, y_valid, ranger_predictions_after_vi_clean$predictions)</code></pre>
<pre><code>## [1] 0.9104619 0.2064781 0.2667099</code></pre>
<p>It seems cleaning YearMade and dropping IDs improved the model just a bit.</p>
</div>
</div>
<div id="conclusions" class="section level2">
<h2>Conclusions</h2>
<p>I manage to fairly quick build a first model that can serve as a baseline in the future experiments. I used variable importance analysis to simplify the model and get the first insights into features that matter for the model. This knowledge could be further used to do more sophisticated feature engineering.</p>
</div>
</div>
